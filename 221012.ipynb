{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연령</th>\n",
       "      <th>감정_대분류</th>\n",
       "      <th>사람문장1</th>\n",
       "      <th>사람문장2</th>\n",
       "      <th>사람문장3</th>\n",
       "      <th>사람문장4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>청년</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>아내가 드디어 출산하게 되어서 정말 신이 나.</td>\n",
       "      <td>아 지금 정말 신이 나.</td>\n",
       "      <td>아기가 점점 클게 벌써 기대가 되네. 내가 많이 놀아줘야지.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>노년</td>\n",
       "      <td>불안</td>\n",
       "      <td>당뇨랑 합병증 때문에 먹어야 할 약이 열 가지가 넘어가니까 스트레스야.</td>\n",
       "      <td>건강할 때 관리 좀 잘할걸 하는 생각이 들더라고.</td>\n",
       "      <td>약을 잘 챙겨 먹고 나을 수 있도록 노력해야지.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>청소년</td>\n",
       "      <td>당황</td>\n",
       "      <td>고등학교에 올라오니 중학교 때보다 수업이 갑자기 어려워져서 당황스러워.</td>\n",
       "      <td>아직 학기 초인데 내가 수업에 잘 따라갈 수 있을지 걱정돼.</td>\n",
       "      <td>중학교 수업을 들을 때보다 훨씬 더 열심히 할 거야.</td>\n",
       "      <td>선생님이 강조하신 부분을 필기하고 집에서 매일 수업 내용을 복습하려고 해.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>노년</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>재취업이 돼서 받게 된 첫 월급으로 온 가족이 외식을 할 예정이야. 너무 행복해.</td>\n",
       "      <td>퇴직 후 다시는 돈을 못 벌 줄 알았는데 이렇게 월급으로 가족에게 맛있는 밥을 살 ...</td>\n",
       "      <td>회사생활을 열심히 해서 계속 월급을 받을거야!</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>노년</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>빚을 드디어 다 갚게 되어서 이제야 안도감이 들어.</td>\n",
       "      <td>빚도 다 갚았으니 당분간은 아무 생각도 안 하며 살고 싶어.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40874</th>\n",
       "      <td>청년</td>\n",
       "      <td>불안</td>\n",
       "      <td>같이 사는 친구가 애완견을 데려왔는데 대부분 내가 돌보고 있어. 내가 주인인가 혼란...</td>\n",
       "      <td>나한테 아예 떠넘길 거 같은데 친구한테 얘기해볼까 고민 중이야.</td>\n",
       "      <td>이대로 내가 키우게 되면 안 되니까 확실하게 해야겠어.</td>\n",
       "      <td>친구가 자기가 데려온 강아지에 대해 책임감을 갖고 스스로 잘 돌봤으면 좋겠어.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40875</th>\n",
       "      <td>중년</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>지난주에 건강검진 결과가 나왔는데 정상이라고 결과가 나왔어.</td>\n",
       "      <td>결과가 좋게 나와서 다행이야</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40876</th>\n",
       "      <td>청소년</td>\n",
       "      <td>슬픔</td>\n",
       "      <td>엄마는 내 꿈인 작가를 응원해 주고는 했는데 지금은 안 그래. 너무 슬퍼.</td>\n",
       "      <td>내 재능이 남들보다 월등한 거는 아니라면서 취업해서 안정적으로 살았으면 좋겠다고 하셔.</td>\n",
       "      <td>내가 다시 내 꿈을 어떻게 이룰 것인지 자세히 설명해 드려야겠어.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40877</th>\n",
       "      <td>노년</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>이렇게 좋은 운동 시설에서 경로 우대로 운동할 수 있다니 참 행운이야.</td>\n",
       "      <td>덕분에 건강도 챙길 수 있고 너무 좋아. 안마기도 있던데 내일은 운동하고 안마기도 ...</td>\n",
       "      <td>운동으로 뭉친 근육을 풀어주는 것 같아. 그럼 덜 피로하겠지.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40878</th>\n",
       "      <td>청년</td>\n",
       "      <td>불안</td>\n",
       "      <td>친구 관계가 너무 힘들어. 베푸는 만큼 돌아오지 않는 것 같아.</td>\n",
       "      <td>카페에 가서 대화하거나 같이 술 마시면서 이야기했던 것 같아.</td>\n",
       "      <td>직접 서운한 감정을 친구에게 얘기하려고 해.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40879 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        연령 감정_대분류                                              사람문장1  \\\n",
       "0       청년     기쁨                          아내가 드디어 출산하게 되어서 정말 신이 나.   \n",
       "1       노년     불안            당뇨랑 합병증 때문에 먹어야 할 약이 열 가지가 넘어가니까 스트레스야.   \n",
       "2      청소년     당황            고등학교에 올라오니 중학교 때보다 수업이 갑자기 어려워져서 당황스러워.   \n",
       "3       노년     기쁨      재취업이 돼서 받게 된 첫 월급으로 온 가족이 외식을 할 예정이야. 너무 행복해.   \n",
       "4       노년     기쁨                       빚을 드디어 다 갚게 되어서 이제야 안도감이 들어.   \n",
       "...    ...    ...                                                ...   \n",
       "40874   청년     불안  같이 사는 친구가 애완견을 데려왔는데 대부분 내가 돌보고 있어. 내가 주인인가 혼란...   \n",
       "40875   중년     기쁨                  지난주에 건강검진 결과가 나왔는데 정상이라고 결과가 나왔어.   \n",
       "40876  청소년     슬픔          엄마는 내 꿈인 작가를 응원해 주고는 했는데 지금은 안 그래. 너무 슬퍼.   \n",
       "40877   노년     기쁨            이렇게 좋은 운동 시설에서 경로 우대로 운동할 수 있다니 참 행운이야.   \n",
       "40878   청년     불안                친구 관계가 너무 힘들어. 베푸는 만큼 돌아오지 않는 것 같아.   \n",
       "\n",
       "                                                   사람문장2  \\\n",
       "0                                          아 지금 정말 신이 나.   \n",
       "1                            건강할 때 관리 좀 잘할걸 하는 생각이 들더라고.   \n",
       "2                      아직 학기 초인데 내가 수업에 잘 따라갈 수 있을지 걱정돼.   \n",
       "3      퇴직 후 다시는 돈을 못 벌 줄 알았는데 이렇게 월급으로 가족에게 맛있는 밥을 살 ...   \n",
       "4                      빚도 다 갚았으니 당분간은 아무 생각도 안 하며 살고 싶어.   \n",
       "...                                                  ...   \n",
       "40874                나한테 아예 떠넘길 거 같은데 친구한테 얘기해볼까 고민 중이야.   \n",
       "40875                                    결과가 좋게 나와서 다행이야   \n",
       "40876   내 재능이 남들보다 월등한 거는 아니라면서 취업해서 안정적으로 살았으면 좋겠다고 하셔.   \n",
       "40877  덕분에 건강도 챙길 수 있고 너무 좋아. 안마기도 있던데 내일은 운동하고 안마기도 ...   \n",
       "40878                 카페에 가서 대화하거나 같이 술 마시면서 이야기했던 것 같아.   \n",
       "\n",
       "                                      사람문장3  \\\n",
       "0        아기가 점점 클게 벌써 기대가 되네. 내가 많이 놀아줘야지.    \n",
       "1                약을 잘 챙겨 먹고 나을 수 있도록 노력해야지.   \n",
       "2             중학교 수업을 들을 때보다 훨씬 더 열심히 할 거야.   \n",
       "3                 회사생활을 열심히 해서 계속 월급을 받을거야!   \n",
       "4                                       NaN   \n",
       "...                                     ...   \n",
       "40874        이대로 내가 키우게 되면 안 되니까 확실하게 해야겠어.   \n",
       "40875                                   NaN   \n",
       "40876  내가 다시 내 꿈을 어떻게 이룰 것인지 자세히 설명해 드려야겠어.   \n",
       "40877    운동으로 뭉친 근육을 풀어주는 것 같아. 그럼 덜 피로하겠지.   \n",
       "40878              직접 서운한 감정을 친구에게 얘기하려고 해.   \n",
       "\n",
       "                                             사람문장4  \n",
       "0                                              NaN  \n",
       "1                                              NaN  \n",
       "2        선생님이 강조하신 부분을 필기하고 집에서 매일 수업 내용을 복습하려고 해.  \n",
       "3                                              NaN  \n",
       "4                                              NaN  \n",
       "...                                            ...  \n",
       "40874  친구가 자기가 데려온 강아지에 대해 책임감을 갖고 스스로 잘 돌봤으면 좋겠어.  \n",
       "40875                                          NaN  \n",
       "40876                                          NaN  \n",
       "40877                                          NaN  \n",
       "40878                                          NaN  \n",
       "\n",
       "[40879 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "path = \"C:\\\\pytest\\\\감성대화말뭉치\\\\\"\n",
    "data = pd.read_excel(path+\"감성대화말뭉치(최종데이터)_Training.xlsx\")\n",
    "random_state = 1111\n",
    "\n",
    "# 연령, 감정 모델 각각 만들기\n",
    "data = data[['연령', '감정_대분류', '사람문장1', '사람문장2', '사람문장3', '사람문장4']]\n",
    "# data = data.fillna('')\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(\n",
    "    columns={'사람문장1': '사람문장', '사람문장2': '사람문장', '사람문장3': '사람문장', '사람문장4': '사람문장'})\n",
    "col_data = pd.concat([data.iloc[:, [0, 1, 2]], data.iloc[:, [\n",
    "                     0, 1, 3]], data.iloc[:, [0, 1, 4]], data.iloc[:, [0, 1, 5]]], axis=0)\n",
    "col_data.dropna(inplace=True)\n",
    "col_data = col_data.reset_index()\n",
    "col_data.drop('index', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath:  c:\\projects\\venv\\lib\\site-packages\n",
      "classpath:  c:\\projects\\venv\\lib\\site-packages\\rhinoMorph/lib/rhino.jar\n",
      "RHINO started!\n"
     ]
    }
   ],
   "source": [
    "import rhinoMorph\n",
    "rn = rhinoMorph.startRhino()\n",
    "\n",
    "\n",
    "def morphed(text):\n",
    "    tmp_list = rhinoMorph.onlyMorph_list(\n",
    "        rn, text, pos=['NNG', 'NNP', 'NP', 'VV', 'VA', 'XR', 'VCN', 'MAG', 'MAJ', 'IC']) #ef, -ic\n",
    "    return ' '.join(tmp_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_data['사람문장_형태소'] = col_data['사람문장'].apply(morphed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연령</th>\n",
       "      <th>감정_대분류</th>\n",
       "      <th>사람문장</th>\n",
       "      <th>사람문장_형태소</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>청년</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>아내가 드디어 출산하게 되어서 정말 신이 나.</td>\n",
       "      <td>아내 드디어 출산 되 정말 신 나</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>노년</td>\n",
       "      <td>불안</td>\n",
       "      <td>당뇨랑 합병증 때문에 먹어야 할 약이 열 가지가 넘어가니까 스트레스야.</td>\n",
       "      <td>당뇨 합병증 약이 가지 넘어가 스트레스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>청소년</td>\n",
       "      <td>당황</td>\n",
       "      <td>고등학교에 올라오니 중학교 때보다 수업이 갑자기 어려워져서 당황스러워.</td>\n",
       "      <td>고등학교 올라오 중학교 때 수업 갑자기 어렵 당황</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>노년</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>재취업이 돼서 받게 된 첫 월급으로 온 가족이 외식을 할 예정이야. 너무 행복해.</td>\n",
       "      <td>재취업 되 받 되 월급 오 가족 외식 하 예정 너무 행복</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>노년</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>빚을 드디어 다 갚게 되어서 이제야 안도감이 들어.</td>\n",
       "      <td>빚 드디어 다 갚 되 이제야 안도감 들</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114284</th>\n",
       "      <td>노년</td>\n",
       "      <td>불안</td>\n",
       "      <td>미리 미리 건강 챙기고 모두 안 아팠으면 좋겠어.</td>\n",
       "      <td>미리 미리 건강 챙기 모두 안 아프 좋</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114285</th>\n",
       "      <td>노년</td>\n",
       "      <td>당황</td>\n",
       "      <td>주변에 믿음직한 사람들에게서 정보도 많이 얻고 달콤한 말은 항상 의심하고 볼래.</td>\n",
       "      <td>주변 믿음직 사람 정보 많이 얻 달콤 말 항상 의심 보</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114286</th>\n",
       "      <td>노년</td>\n",
       "      <td>불안</td>\n",
       "      <td>친구들에게 내 마음을 터놓고 얘기하면 좀 나아질 것 같아.</td>\n",
       "      <td>친구 나 마음 터놓 이야기 좀 낫 같</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114287</th>\n",
       "      <td>노년</td>\n",
       "      <td>당황</td>\n",
       "      <td>남편에게 이런 내 마음을 솔직하게 얘기해 봐야겠어.</td>\n",
       "      <td>남편 나 마음 솔직 이야기</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114288</th>\n",
       "      <td>청년</td>\n",
       "      <td>불안</td>\n",
       "      <td>친구가 자기가 데려온 강아지에 대해 책임감을 갖고 스스로 잘 돌봤으면 좋겠어.</td>\n",
       "      <td>친구 자기 데리 강아지 대하 책임감 갖 스스로 잘 돌 좋</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114289 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         연령 감정_대분류                                           사람문장  \\\n",
       "0        청년     기쁨                      아내가 드디어 출산하게 되어서 정말 신이 나.   \n",
       "1        노년     불안        당뇨랑 합병증 때문에 먹어야 할 약이 열 가지가 넘어가니까 스트레스야.   \n",
       "2       청소년     당황        고등학교에 올라오니 중학교 때보다 수업이 갑자기 어려워져서 당황스러워.   \n",
       "3        노년     기쁨  재취업이 돼서 받게 된 첫 월급으로 온 가족이 외식을 할 예정이야. 너무 행복해.   \n",
       "4        노년     기쁨                   빚을 드디어 다 갚게 되어서 이제야 안도감이 들어.   \n",
       "...     ...    ...                                            ...   \n",
       "114284   노년     불안                    미리 미리 건강 챙기고 모두 안 아팠으면 좋겠어.   \n",
       "114285   노년     당황   주변에 믿음직한 사람들에게서 정보도 많이 얻고 달콤한 말은 항상 의심하고 볼래.   \n",
       "114286   노년     불안               친구들에게 내 마음을 터놓고 얘기하면 좀 나아질 것 같아.   \n",
       "114287   노년     당황                   남편에게 이런 내 마음을 솔직하게 얘기해 봐야겠어.   \n",
       "114288   청년     불안    친구가 자기가 데려온 강아지에 대해 책임감을 갖고 스스로 잘 돌봤으면 좋겠어.   \n",
       "\n",
       "                               사람문장_형태소  \n",
       "0                    아내 드디어 출산 되 정말 신 나  \n",
       "1                 당뇨 합병증 약이 가지 넘어가 스트레스  \n",
       "2           고등학교 올라오 중학교 때 수업 갑자기 어렵 당황  \n",
       "3       재취업 되 받 되 월급 오 가족 외식 하 예정 너무 행복  \n",
       "4                 빚 드디어 다 갚 되 이제야 안도감 들  \n",
       "...                                 ...  \n",
       "114284            미리 미리 건강 챙기 모두 안 아프 좋  \n",
       "114285   주변 믿음직 사람 정보 많이 얻 달콤 말 항상 의심 보  \n",
       "114286             친구 나 마음 터놓 이야기 좀 낫 같  \n",
       "114287                   남편 나 마음 솔직 이야기  \n",
       "114288  친구 자기 데리 강아지 대하 책임감 갖 스스로 잘 돌 좋  \n",
       "\n",
       "[114289 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "연령_X_pre, 연령_X_test, 연령_y_pre, 연령_y_test = train_test_split(\n",
    "    col_data.iloc[:, -1], col_data.iloc[:, 0], random_state=random_state, test_size=.3)\n",
    "연령_X_train, 연령_X_validation, 연령_y_train, 연령_y_validation = train_test_split(\n",
    "    연령_X_pre, 연령_y_pre, random_state=random_state, test_size=.1)\n",
    "# test 데이터는 앞에서 3000건만 취하고 나머지 버림\n",
    "연령_X_test = 연령_X_test[:3000]\n",
    "연령_y_test = 연령_y_test[:3000]\n",
    "\n",
    "감정_X_pre, 감정_X_test, 감정_y_pre, 감정_y_test = train_test_split(\n",
    "    col_data.iloc[:, -1], col_data.iloc[:, 1], random_state=random_state, test_size=.3)\n",
    "감정_X_train, 감정_X_validation, 감정_y_train, 감정_y_validation = train_test_split(\n",
    "    감정_X_pre, 감정_y_pre, random_state=random_state, test_size=.1)\n",
    "# test 데이터는 앞에서 3000건만 취하고 나머지 버림\n",
    "감정_X_test = 감정_X_test[:3000]\n",
    "감정_y_test = 감정_y_test[:3000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최소길이: 1\n",
      "최대길이: 31\n",
      "평균길이: 8.2\n",
      "중위수길이: 8.0\n",
      "구간별 최대 길이: [ 1.  6. 10. 12. 13. 14. 15. 17. 31.]\n",
      "최소길이 문장: 갱년기\n",
      "최대길이 문장: 응 직속 상사 잘못 하 일 나 떠넘기 나 말 못 하 결국 욕 먹 힘들 일 관두 이러 알 나 하 일 아니 그때 말 하 그리하 정말 후회 되\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "text_len = [len(line.split()) for line in 연령_X_train]\n",
    "print(f\"최소길이: {np.min(text_len)}\")\n",
    "print(f\"최대길이: {np.max(text_len)}\")\n",
    "print(f\"평균길이: {np.round(np.mean(text_len),1)}\")\n",
    "print(f\"중위수길이: {np.median(text_len)}\")\n",
    "print(f\"구간별 최대 길이: {np.percentile(text_len, [0,25,75,90,95,97,98,99,100])}\")\n",
    "print(f\"최소길이 문장: {연령_X_train.iloc[np.argmin(text_len)]}\")\n",
    "print(f\"최대길이 문장: {연령_X_train.iloc[np.argmax(text_len)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "from collections import Counter\n",
    "\n",
    "a_text_list = [line.split() for line in 연령_X_train]\n",
    "b_text_len = [line.split() for line in 연령_X_validation]\n",
    "c_text_len = [line.split() for line in 연령_X_test]\n",
    "\n",
    "a_data = []\n",
    "for i in a_text_list:\n",
    "    for j in i:\n",
    "        a_data.append(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12075\n"
     ]
    }
   ],
   "source": [
    "a = Counter(a_data)\n",
    "\n",
    "# print(f\"train_data_label_freq:\", a)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "max_words=3000\n",
    "maxlen=18\n",
    "\n",
    "tokenizer=Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(a_text_list)\n",
    "word_index=tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([k for k in a if a[k] > 100]) # 50번 이상 나오는 단어는 1266, 100번 이상 나오는 단어는 800개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70719                  아무렇 틈 나 나 머리채 쥐 괴롭히 있\n",
       "15637            친구 생일 선물 예쁘 가방 다 바쁘 정말 고맙 있\n",
       "103541                   응 그래도 꿈 포기 다시 한번 도전\n",
       "35869                 나이 마음 들 친구 없 상황 너무나 슬프\n",
       "78275       남편 아이 그렇게 생각 정말 모르 그동안 아이 관심 도 없\n",
       "                         ...                \n",
       "91862              나 아직 아프 더 알 솔직 마음 이야기 하 보\n",
       "87866     나 능력 정확 평가 그것 반영해 연봉 잘 올리 점 가장 좋 점\n",
       "21228                  출산 앞두 아내 혼자 때 일 생기 걱정\n",
       "78029                     처음 작 점점 커지 같 미관 걱정\n",
       "24993                   점심시간 나 항상 밥 혼자 쓸쓸 외롭\n",
       "Name: 사람문장_형태소, Length: 72001, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "연령_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대문장길이:  31\n",
      "최소문장길이:  0\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0 1546 1974\n",
      "    1    1  165    7]\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "data = tokenizer.texts_to_sequences(연령_X_train)\n",
    "# print(\"data:\", data)\n",
    "len_d= [len(d) for d in data]\n",
    "# print(\"길이\", len_d)\n",
    "print(\"최대문장길이: \", max(len_d))\n",
    "print(\"최소문장길이: \", min(len_d))\n",
    "\n",
    "연령_X_train_data = pad_sequences(data, maxlen=maxlen)\n",
    "print(연령_X_train_data[0])\n",
    "print(len(연령_X_train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대문장길이:  25\n",
      "최소문장길이:  1\n",
      "[   0    0    0    0    0    0    0   59 1672   16   95   74  161  247\n",
      " 1419  566   75    4]\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "data = tokenizer.texts_to_sequences(연령_X_validation)\n",
    "# print(\"data:\", data)\n",
    "len_d= [len(d) for d in data]\n",
    "# print(\"길이\", len_d)\n",
    "print(\"최대문장길이: \", max(len_d))\n",
    "print(\"최소문장길이: \", min(len_d))\n",
    "\n",
    "연령_X_validation_data = pad_sequences(data, maxlen=maxlen)\n",
    "print(연령_X_validation_data[0])\n",
    "print(len(연령_X_validation_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대문장길이:  28\n",
      "최소문장길이:  1\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0 2280 1367 1616]\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "data = tokenizer.texts_to_sequences(연령_X_test)\n",
    "# print(\"data:\", data)\n",
    "len_d= [len(d) for d in data]\n",
    "# print(\"길이\", len_d)\n",
    "print(\"최대문장길이: \", max(len_d))\n",
    "print(\"최소문장길이: \", min(len_d))\n",
    "\n",
    "연령_X_test_data = pad_sequences(data, maxlen=maxlen)\n",
    "print(연령_X_test_data[0])\n",
    "print(len(연령_X_test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대문장길이:  31\n",
      "최소문장길이:  0\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0 1546 1974\n",
      "    1    1  165    7]\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "data = tokenizer.texts_to_sequences(감정_X_train)\n",
    "# print(\"data:\", data)\n",
    "len_d= [len(d) for d in data]\n",
    "# print(\"길이\", len_d)\n",
    "print(\"최대문장길이: \", max(len_d))\n",
    "print(\"최소문장길이: \", min(len_d))\n",
    "\n",
    "감정_X_train_data = pad_sequences(data, maxlen=maxlen)\n",
    "print(감정_X_train_data[0])\n",
    "print(len(감정_X_train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 2280, 1367, 1616],\n",
       "       [   0,    0,    0, ...,   98,   27,   81],\n",
       "       [   0,    0,    0, ...,  126,  591,  529],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   89,   36,  184],\n",
       "       [   0,    0,    0, ...,  464,  105,    2],\n",
       "       [   0,    0,    0, ...,   23,   56,  111]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "연령_X_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    1,  165,    7],\n",
       "       [   0,    0,    0, ...,   23,  189,    7],\n",
       "       [   0,    0,    0, ...,  105,  294, 1061],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   17,  104,   24],\n",
       "       [   0,    0,    0, ..., 1096,    4,   24],\n",
       "       [   0,    0,    0, ...,   75,  912,  180]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "감정_X_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대문장길이:  25\n",
      "최소문장길이:  1\n",
      "[   0    0    0    0    0    0    0   59 1672   16   95   74  161  247\n",
      " 1419  566   75    4]\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "data = tokenizer.texts_to_sequences(감정_X_validation)\n",
    "# print(\"data:\", data)\n",
    "len_d= [len(d) for d in data]\n",
    "# print(\"길이\", len_d)\n",
    "print(\"최대문장길이: \", max(len_d))\n",
    "print(\"최소문장길이: \", min(len_d))\n",
    "\n",
    "감정_X_validation_data = pad_sequences(data, maxlen=maxlen)\n",
    "print(감정_X_validation_data[0])\n",
    "print(len(감정_X_validation_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대문장길이:  28\n",
      "최소문장길이:  1\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0 2280 1367 1616]\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "data = tokenizer.texts_to_sequences(감정_X_test)\n",
    "# print(\"data:\", data)\n",
    "len_d= [len(d) for d in data]\n",
    "# print(\"길이\", len_d)\n",
    "print(\"최대문장길이: \", max(len_d))\n",
    "print(\"최소문장길이: \", min(len_d))\n",
    "\n",
    "감정_X_test_data = pad_sequences(data, maxlen=maxlen)\n",
    "print(감정_X_test_data[0])\n",
    "print(len(감정_X_test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "def to_one_hot(sequences, dimension):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "연령_X_train_data_one_hot_encoding = to_one_hot(연령_X_train_data, dimension=max_words)\n",
    "연령_X_validation_data_one_hot_encoding = to_one_hot(연령_X_validation_data, dimension=max_words)\n",
    "연령_X_test_data_one_hot_encoding = to_one_hot(연령_X_test_data, dimension=max_words)\n",
    "감정_X_train_data_one_hot_encoding = to_one_hot(감정_X_train_data, dimension=max_words)\n",
    "감정_X_validation_data_one_hot_encoding = to_one_hot(감정_X_validation_data, dimension=max_words)\n",
    "감정_X_test_data_one_hot_encoding = to_one_hot(감정_X_test_data, dimension=max_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72001, 3000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연령_y_train\n",
    "# 연령_y_validation\n",
    "# 연령_y_test\n",
    "# 감정_y_train\n",
    "# 감정_y_validation\n",
    "# 감정_y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "def to_one_hot(sequences, dimension):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences.values):\n",
    "        results[i, sequence] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'청소년': 0, '청년': 1, '중년': 2, '노년': 3}\n"
     ]
    }
   ],
   "source": [
    "empty_dict = dict()\n",
    "연령_y_train_one_hot_encoding = 연령_y_train.copy()\n",
    "연령_y_validation_one_hot_encoding = 연령_y_validation.copy()\n",
    "연령_y_test_one_hot_encoding = 연령_y_test.copy()\n",
    "for idx, v in enumerate(연령_y_train.unique()):\n",
    "    empty_dict[v] = idx\n",
    "print(empty_dict)\n",
    "for i in empty_dict:\n",
    "    연령_y_train_one_hot_encoding = 연령_y_train_one_hot_encoding.replace(i, empty_dict[i])\n",
    "    연령_y_validation_one_hot_encoding = 연령_y_validation_one_hot_encoding.replace(i, empty_dict[i])\n",
    "    연령_y_test_one_hot_encoding = 연령_y_test_one_hot_encoding.replace(i, empty_dict[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70719     청소년\n",
       "15637      청년\n",
       "103541     중년\n",
       "35869      노년\n",
       "78275      중년\n",
       "         ... \n",
       "91862      노년\n",
       "87866      중년\n",
       "21228      청년\n",
       "78029      중년\n",
       "24993     청소년\n",
       "Name: 연령, Length: 72001, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "연령_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70719     0\n",
       "15637     1\n",
       "103541    2\n",
       "35869     3\n",
       "78275     2\n",
       "         ..\n",
       "91862     3\n",
       "87866     2\n",
       "21228     1\n",
       "78029     2\n",
       "24993     0\n",
       "Name: 연령, Length: 72001, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "연령_y_train_one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "연령_y_train_one_hot_encoding = to_one_hot(연령_y_train_one_hot_encoding, dimension=4)\n",
    "연령_y_validation_one_hot_encoding = to_one_hot(연령_y_validation_one_hot_encoding, dimension=4)\n",
    "연령_y_test_one_hot_encoding = to_one_hot(연령_y_test_one_hot_encoding, dimension=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "연령_y_train_one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'분노': 0, '기쁨': 1, '슬픔': 2, '당황': 3, '상처': 4, '불안': 5, '기쁨 ': 6, '불안 ': 7}\n"
     ]
    }
   ],
   "source": [
    "empty_dict = dict()\n",
    "감정_y_train_one_hot_encoding = 감정_y_train.copy()\n",
    "감정_y_validation_one_hot_encoding = 감정_y_validation.copy()\n",
    "감정_y_test_one_hot_encoding = 감정_y_test.copy()\n",
    "for idx, v in enumerate(감정_y_train.unique()):\n",
    "    empty_dict[v] = idx\n",
    "print(empty_dict)\n",
    "for i in empty_dict:\n",
    "    감정_y_train_one_hot_encoding = 감정_y_train_one_hot_encoding.replace(i, empty_dict[i])\n",
    "    감정_y_validation_one_hot_encoding = 감정_y_validation_one_hot_encoding.replace(i, empty_dict[i])\n",
    "    감정_y_test_one_hot_encoding = 감정_y_test_one_hot_encoding.replace(i, empty_dict[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "감정_y_train_one_hot_encoding = to_one_hot(감정_y_train_one_hot_encoding, dimension=len(empty_dict))\n",
    "감정_y_validation_one_hot_encoding = to_one_hot(감정_y_validation_one_hot_encoding, dimension=len(empty_dict))\n",
    "감정_y_test_one_hot_encoding = to_one_hot(감정_y_test_one_hot_encoding, dimension=len(empty_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                192064    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194,276\n",
      "Trainable params: 194,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "58021/72001 [=======================>......] - ETA: 1:17 - loss: 1.3714 - acc: 0.3051"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3380\\50184114.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mearlystop_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mcp_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m연령_X_train_data_one_hot_encoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m연령_y_train_one_hot_encoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m연령_X_validation_data_one_hot_encoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m연령_y_validation_one_hot_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearlystop_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcp_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mhistory_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\projects\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\projects\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\projects\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\projects\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\projects\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\projects\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2497\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2499\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\projects\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1862\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1863\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\projects\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\projects\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size= 1\n",
    "model_name= 'c:\\\\projects\\\\model\\\\221012\\\\train_data_morphed.h5'\n",
    "tokenizer_name= 'c:\\\\projects\\\\model\\\\221012\\\\train_data_morphed.pickle'\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(연령_X_train_data_one_hot_encoding.shape[1],)))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=연령_y_train_one_hot_encoding.shape[1], activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics='acc')\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "earlystop_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "cp_callback = ModelCheckpoint(filepath=model_name, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "history = model.fit(연령_X_train_data_one_hot_encoding, 연령_y_train_one_hot_encoding, epochs=epochs, batch_size=batch_size, validation_data=(연령_X_validation_data_one_hot_encoding, 연령_y_validation_one_hot_encoding), callbacks=[earlystop_callback, cp_callback], verbose=1)\n",
    "history_dict = history.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_17 (Dense)            (None, 64)                64064     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,408\n",
      "Trainable params: 66,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2249/2251 [============================>.] - ETA: 0s - loss: 1.8112 - acc: 0.1738\n",
      "Epoch 1: val_loss improved from inf to 1.79264, saving model to c:\\projects\\model\\221012\\train_data_morphed_2.h5\n",
      "2251/2251 [==============================] - 12s 5ms/step - loss: 1.8112 - acc: 0.1738 - val_loss: 1.7926 - val_acc: 0.1670\n",
      "Epoch 2/20\n",
      "2242/2251 [============================>.] - ETA: 0s - loss: 1.7925 - acc: 0.1766\n",
      "Epoch 2: val_loss improved from 1.79264 to 1.79097, saving model to c:\\projects\\model\\221012\\train_data_morphed_2.h5\n",
      "2251/2251 [==============================] - 11s 5ms/step - loss: 1.7925 - acc: 0.1766 - val_loss: 1.7910 - val_acc: 0.1817\n",
      "Epoch 3/20\n",
      "2245/2251 [============================>.] - ETA: 0s - loss: 1.7924 - acc: 0.1742\n",
      "Epoch 3: val_loss improved from 1.79097 to 1.79079, saving model to c:\\projects\\model\\221012\\train_data_morphed_2.h5\n",
      "2251/2251 [==============================] - 11s 5ms/step - loss: 1.7924 - acc: 0.1742 - val_loss: 1.7908 - val_acc: 0.1817\n",
      "Epoch 4/20\n",
      "2248/2251 [============================>.] - ETA: 0s - loss: 1.7922 - acc: 0.1755\n",
      "Epoch 4: val_loss did not improve from 1.79079\n",
      "2251/2251 [==============================] - 10s 5ms/step - loss: 1.7922 - acc: 0.1755 - val_loss: 1.7911 - val_acc: 0.1817\n",
      "Epoch 5/20\n",
      "2243/2251 [============================>.] - ETA: 0s - loss: 1.7921 - acc: 0.1760\n",
      "Epoch 5: val_loss did not improve from 1.79079\n",
      "2251/2251 [==============================] - 12s 5ms/step - loss: 1.7921 - acc: 0.1760 - val_loss: 1.7909 - val_acc: 0.1817\n",
      "Epoch 6/20\n",
      "2247/2251 [============================>.] - ETA: 0s - loss: 1.7921 - acc: 0.1759\n",
      "Epoch 6: val_loss did not improve from 1.79079\n",
      "2251/2251 [==============================] - 13s 6ms/step - loss: 1.7921 - acc: 0.1758 - val_loss: 1.7909 - val_acc: 0.1817\n",
      "Epoch 7/20\n",
      "2243/2251 [============================>.] - ETA: 0s - loss: 1.7921 - acc: 0.1765\n",
      "Epoch 7: val_loss did not improve from 1.79079\n",
      "2251/2251 [==============================] - 13s 6ms/step - loss: 1.7921 - acc: 0.1765 - val_loss: 1.7909 - val_acc: 0.1817\n",
      "Epoch 8/20\n",
      "2248/2251 [============================>.] - ETA: 0s - loss: 1.7920 - acc: 0.1763\n",
      "Epoch 8: val_loss did not improve from 1.79079\n",
      "2251/2251 [==============================] - 13s 6ms/step - loss: 1.7920 - acc: 0.1763 - val_loss: 1.7910 - val_acc: 0.1816\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size= 32\n",
    "model_name= 'c:\\\\projects\\\\model\\\\221012\\\\train_data_morphed_2.h5'\n",
    "tokenizer_name= 'c:\\\\projects\\\\model\\\\221012\\\\train_data_morphed_2.pickle'\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(감정_X_train_data_one_hot_encoding.shape[1],)))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=감정_y_train_one_hot_encoding.shape[1], activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics='acc')\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "earlystop_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "cp_callback = ModelCheckpoint(filepath=model_name, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "history = model.fit(감정_X_train_data_one_hot_encoding, 감정_y_train_one_hot_encoding, epochs=epochs, batch_size=batch_size, validation_data=(감정_X_validation_data_one_hot_encoding, 감정_y_validation_one_hot_encoding), callbacks=[earlystop_callback, cp_callback], verbose=1)\n",
    "history_dict = history.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee3a569b6c17f781d88eed465009cab3acc13ebf6747bed2a2b2f4afb9b22959"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
